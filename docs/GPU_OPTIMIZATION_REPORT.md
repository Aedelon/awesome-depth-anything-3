# üöÄ Optimisation Pipeline: GPU Preprocessing & NVJPEG

Ce document d√©taille les optimisations apport√©es au pipeline de pr√©-traitement d'images de `depth-anything-3`, visant √† r√©duire la latence d'inf√©rence, en particulier pour les hautes r√©solutions (4K) et les flux vid√©o.

## üìä R√©sultats du Benchmark (NVIDIA L4)

Les tests ont compar√© quatre strat√©gies diff√©rentes sur un lot de 4 images avec 8 workers.

| R√©solution | M√©thode CPU (Ref) | M√©thode Full GPU (Kornia) | M√©thode Hybride | **M√©thode GPU Decode (NVJPEG)** | **Gain vs CPU** |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **VGA** (640x480) | 35.0 ms | 20.6 ms | 17.4 ms | **10.8 ms** | **x 3.2** |
| **HD** (1280x720) | 33.8 ms | 44.8 ms | 28.2 ms | **17.6 ms** | **x 1.9** |
| **FHD** (1920x1080) | 53.2 ms | 97.2 ms | 46.5 ms | **18.3 ms** | **x 2.9** |
| **4K** (3840x2160) | 222.5 ms | 436.3 ms | 209.5 ms | **54.0 ms** | **x 4.1** üöÄ |

### Analyse
1.  **GPU Decode (NVJPEG) est dominant :** En lisant directement le fichier JPEG et en le d√©codant via l'acc√©l√©ration mat√©rielle du GPU, on √©limine le goulot d'√©tranglement du d√©codage CPU et le transfert co√ªteux de bitmaps non compress√©s sur le bus PCI-e.
2.  **Limites du "Full GPU" classique :** L'approche na√Øve (charger sur CPU -> transf√©rer -> resize GPU) devient **2x plus lente** que le CPU pour la 4K √† cause de la latence de transfert m√©moire.
3.  **Efficacit√© de la M√©thode Hybride :** Pour les images d√©j√† en m√©moire (ex: flux vid√©o d√©cod√© ailleurs), l'approche Hybride (Resize CPU -> Transfert uint8 -> Norm GPU) offre un gain constant sans overhead.

---

## üõ†Ô∏è Strat√©gies Impl√©ment√©es

Le syst√®me s√©lectionne automatiquement la strat√©gie optimale en fonction du mat√©riel et du type d'entr√©e.

### 1. üü¢ GPU Decode (Fichiers + CUDA/MPS)
*   **Cible :** Inf√©rence CLI, Traitement par lots depuis le disque.
*   **Technique CUDA :** Utilise `nvjpeg` (via `torchvision`) pour d√©coder le JPEG directement dans la m√©moire GPU.
*   **Technique MPS :** Utilise les API natives optimis√©es (ImageIO/Accelerate) pour d√©coder et transf√©rer imm√©diatement.
*   **Flux :** `File Bytes` ‚Üí `Decoder (HW/Opt)` ‚Üí `GPU Memory` ‚Üí `Kornia Resize/Norm`.

### 2. üü° Mode Hybride (Objets M√©moire + GPU)
*   **Cible :** API Python, Webcams, Flux vid√©o o√π l'image est d√©j√† un array numpy/PIL.
*   **Technique :** Effectue le redimensionnement sur CPU (rapide et parall√®le), mais retarde la normalisation et la conversion float.
*   **Avantage :** Transf√®re des donn√©es `uint8` (4x plus l√©g√®res que `float32`) vers le GPU, r√©duisant la saturation de la bande passante.

### 3. üî¥ Mode CPU Standard (Fallback)
*   **Cible :** Machines sans GPU d√©di√©.
*   **Technique :** Pipeline classique utilisant `PIL` et `numpy` avec parall√©lisation multiprocessing.

---

## üíª Architecture du Code

### `src/depth_anything_3/api.py`
*   **D√©tection Auto :** Configure automatiquement `GPUInputProcessor` si un GPU (NVIDIA ou Apple Silicon) est disponible.
*   **Pipeline Intelligent :** Ajuste dynamiquement les √©tapes de normalisation selon que les donn√©es arrivent du CPU ou sont d√©j√† sur le GPU.

### `src/depth_anything_3/utils/io/gpu_input_processor.py`
*   **Support NVJPEG :** Int√©gration de `torchvision.io.decode_jpeg`.
*   **Support MPS :** Compatibilit√© assur√©e pour les puces M1/M2/M3.
*   **Kornia :** Utilisation de Kornia pour les op√©rations g√©om√©triques (Resize, CenterCrop) directement sur les tenseurs GPU.

### `benchmarks/gpu_preprocessing_benchmark.py`
*   Nouveau script de benchmark inclus pour valider les performances sur votre mat√©riel sp√©cifique.
*   Test : `uv run python benchmarks/gpu_preprocessing_benchmark.py`
